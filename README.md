
# GRU Trade Engine

**Status:** Needs testing

**Version:** 0.0.3 | Incomplete

**Supported OS:** Linux

**Hardware Requirements:**  | ~8 GB of ram  |  ~12 GB storage,  |  a decently fast CPU  |  GPU not a requirement

## Overview
<img width="1884" height="1060" alt="Screenshot From 2025-09-07 12-48-11" src="https://github.com/user-attachments/assets/8d1e0ea6-ccc4-417f-a2a4-8bc4a8fef0e8" />

This project is based around making time series predicitons using GRU architecture. Built on this, there are:

- **ğŸ§  ML-Powered Predictions**: Main predictive power comes from the Time Series Regression model trained on stock-price patterns (GRU architecture)
- **ğŸ“Š Automated trading**: Using the IB trading api, this project can follow various time schedules and automatically trade based off of predictions.
- **ğŸ¤– Automated Scheduling**: Background jobs for data collection and predictions
- **ğŸ“ˆ Performance Analytics**: Comprehensive metrics including history and logs
- **ğŸ˜Š Sentiment Analysis**: BERT-based market sentiment from daily web sources (YouTube transcripts - filtered to most recent)

## ğŸ“ Project Structure

```
TSR_trade_engine/
â”œâ”€â”€ README.md                        # Project documentation
â”œâ”€â”€ backend_&_algorithms/            # Core ML and trading engine
â”‚   â”œâ”€â”€ main.py                      # CLI application entry point
â”‚   â”œâ”€â”€ config.json                  # Configuration settings
â”‚   â”œâ”€â”€ install.sh                   # Installation script
â”‚   â”œâ”€â”€ models/                      # Trained model storage
â”‚   â”œâ”€â”€ processed_data/              # Processed training data
â”‚   â”œâ”€â”€ saved_models/                # Saved model checkpoints
â”‚   â”œâ”€â”€ testing/                     # Test files and scripts
â”‚   â”œâ”€â”€ engine/                      # Core engine package
â”‚   â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”‚   â”œâ”€â”€ requirements.txt         # Engine dependencies
â”‚   â”‚   â”œâ”€â”€ setup.py                 # Package setup
â”‚   â”‚   â”œâ”€â”€ tsr_model/               # Time Series Regression models
â”‚   â”‚   â”‚   â”œâ”€â”€ api.py               # High-level API functions
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py            # Neural network architectures
â”‚   â”‚   â”‚   â”œâ”€â”€ training.py          # Model training pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ data_pipelines/      # Data processing pipelines
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py      # Pipeline package
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ price_data.py    # Price & technical data
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stock_data_sources.py # Data source utilities
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tsr_pipeline.py  # TSR-specific pipeline
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py          # TSR model package
â”‚   â”‚   â””â”€â”€ sentiment_model/         # Sentiment analysis
â”‚   â”‚       â”œâ”€â”€ api.py               # Sentiment API functions
â”‚   â”‚       â”œâ”€â”€ model.py             # BERT-based sentiment model
â”‚   â”‚       â”œâ”€â”€ tokenize_pipeline.py # Text processing pipeline
â”‚   â”‚       â”œâ”€â”€ train_with_labeled_data.py # Training script
â”‚   â”‚       â”œâ”€â”€ download_dataset.py  # Dataset utilities
â”‚   â”‚       â”œâ”€â”€ processed_data/      # Tokenized training data
â”‚   â”‚       â”œâ”€â”€ saved_models/        # Trained sentiment models
â”‚   â”‚       â”œâ”€â”€ web_scraper/         # C++ web scraping tools
â”‚   â”‚       â”‚   â”œâ”€â”€ CMakeLists.txt   # Build configuration
â”‚   â”‚       â”‚   â”œâ”€â”€ README.md        # Scraper documentation
â”‚   â”‚       â”‚   â””â”€â”€ tests/           # Unit tests
â”‚   â”‚       â””â”€â”€ __init__.py          # Sentiment model package
â”‚   â””â”€â”€ performance_data/            # Model performance logs
â”‚       â”œâ”€â”€ INFO.md                  # Performance documentation
â”‚       â”œâ”€â”€ generalizing_tsr_model/  # Generalized model results
â”‚       â””â”€â”€ specialized_tsr_model/   # Specialized model results
â”œâ”€â”€ integrations_&_strategy/         # Trading automation and integration
â”‚   â”œâ”€â”€ automated_trader.py          # Main automated trading script
â”‚   â”œâ”€â”€ schedule_trader.py           # Scheduling and automation
â”‚   â”œâ”€â”€ config.json                  # Trading configuration
â”‚   â”œâ”€â”€ requirements.txt             # Integration dependencies
â”‚   â””â”€â”€ README.md                    # Integration documentation
â””â”€â”€ automated_setup.sh               # Complete project setup script
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- Interactive Brokers account and Trader Workstation (The IB app) installed. <-- This is essentially your stock-market API

### Quick Installation & Setup

**Option 1: Automated Setup (Recommended)**
```bash
git clone https://github.com/yourusername/neural_trade_engine.git
cd neural_trade_engine
chmod +x interact.sh
./interact.sh
```
The automated setup will guide you through:
1. **Dependency Installation**: Python packages and system requirements & venv
2. **Sentiment Model Training**: Sentiment model training on a twitter 1.2M labelled database
3. **Stock Selection**: Choose your target stock and semantic name 
4. **Data Collection**: Historical price data and web scraping
5. **Model Training**: TSR/GRU model training on your selected stock (they are trained on a specific stock's history)
6. **Configuration**: Trading parameters and risk settings (optional- use for modifying hyper-parameters)
7. **Trading Mode Selection**: Choose simulation, paper, or live trading

You can use this interface to get your engine actively running on your hardware, no extra steps neccesary.

---

### Architectures

#### Time Series Regression (TSR/GRU) Model
```
Input Layer (50-100 features)
    â”œâ”€â”€ Price Features: OHLCV data, returns, volatility measures
    â”œâ”€â”€ Technical Indicators: Moving averages, RSI, MACD, Bollinger Bands
    â”œâ”€â”€ Volume Features: Volume patterns, Money Flow Index, OBV
    â”œâ”€â”€ Sentiment Features: Aggregated sentiment scores and momentum
    â””â”€â”€ Market Features: VIX levels, sector performance, market breadth

Hidden Layers (3-5 layers)
    â”œâ”€â”€ Dense Layer 1: 256 neurons, ReLU activation, 30% dropout
    â”œâ”€â”€ Dense Layer 2: 128 neurons, ReLU activation, 30% dropout  
    â”œâ”€â”€ Dense Layer 3: 64 neurons, ReLU activation, 20% dropout
    â””â”€â”€ Optional LSTM Layer: 32 cells for temporal sequence learning

Output Layer
    â”œâ”€â”€ Price Prediction: Next day closing price (regression)
    â”œâ”€â”€ Confidence Score: Model certainty (0-1 probability)
    â””â”€â”€ Risk Estimate: Predicted volatility for position sizing
```


- **Models are Specialized**: I use a single-stock model, trained on 2+ years of data for maximum accuracy, as this has proven to perform the best in my testing.

#### Sentiment Analysis Architecture
```
BERT-base-uncased (110M parameters)
    â”œâ”€â”€ Input: Tokenized text from financial news, social media, earnings calls
    â”œâ”€â”€ Embedding: 768-dimensional token embeddings
    â”œâ”€â”€ Transformer Layers: 12 layers with multi-head attention
    â”œâ”€â”€ Classification Head: 3-class sentiment (Bullish/Neutral/Bearish)
    â””â”€â”€ Output: Sentiment probability distribution and confidence score
```


### Data Pipeline & Feature Engineering

#### Enhanced Real-Time Data Flow with Sentiment Integration
```
Market Data  â†’  Data cleaning & normalization   â†’   Model Inference
                                                                â†“
Sentiment Scraping â†’  Sentiment Analysis â†’  Sentiment Bias â†’ Signal Generation â†’ Trade Execution
     â†‘                                                            â†“
Semantic Names (nvidia, apple, tesla, etc.)                Logging & Monitoring
```

**Feature Engineering Pipeline:**
1. **Price Normalization**: Log returns, Z-score normalization
2. **Technical Indicators**: 
   - Trend: SMA(5,10,20,50), EMA(12,26), MACD, ADX
   - Momentum: RSI(14), Stochastic, Williams %R
   - Volatility: Bollinger Bands, ATR, VIX correlation
   - Volume: OBV, Money Flow Index, VWAP
3. **Sentiment Aggregation**: 
   - Temporal sampling (collecting data filtered to be recent)
   - Source reliability scoring
   - Sentiment momentum calculation
4. **Market Regime Detection**: Bull/bear market classification
5. **Risk Factors**: Correlation with market indices, beta calculation

## ğŸ”§ Advanced Configuration

### Model Hyperparameters

```json
{
  
  "sentiment_model": {
    "model_name": "bert-base-uncased",
    "max_sequence_length": 512,
    "learning_rate": 2e-5,
    "warmup_steps": 1000,
    "num_train_epochs": 3
  }
}

```

### Trading Parameters
```json
{
  "risk_management": {
    "max_position_size": 0.95,
    "stop_loss_percent": 0.05,
    "take_profit_percent": 0.10,
    "confidence_threshold": 0.65,
    "minimum_return_threshold": 0.02,
    "sentiment_bias_strength": 0.15
  },
  "execution": {
    "order_type": "market",
    "max_slippage": 0.001,
    "position_sizing_method": "kelly_criterion",
    "rebalance_frequency": "daily"
  },
  "data_sources": {
    "price_data": "interactive_brokers",
    "sentiment_sources": ["financial_news", "social_media"],
    "update_frequency": "1h"
  }
}
```

---

## âš ï¸ Risk Disclaimer & Best Practices

### Known Limitations
- **Market Regime Changes**: Models may underperform during unusual market conditions
- **Black Swan Events**: System cannot predict extreme, unpredictable events
- **Data Dependencies**: Performance relies on quality of input data
- **Execution Risk**: Slippage and latency can impact theoretical performance

---

### Contributing
Contributions are welcome! Please see CONTRIBUTING.md for guidelines on:
- Code style and standards
- Testing requirements  
- Pull request process
- Bug reporting

---

**âš ï¸ FINAL DISCLAIMER: This software is for educational and research purposes. Trading involves substantial risk of loss. The authors assume no responsibility for financial losses. Always conduct thorough testing and consider your risk tolerance before live trading.**

